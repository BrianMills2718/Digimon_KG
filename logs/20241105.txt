2024-11-05 11:39:35.172 | DEBUG    | metagpt.provider.base_llm:aask:151 - [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello world'}]
2024-11-05 11:45:18.561 | DEBUG    | metagpt.provider.base_llm:aask:151 - [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello world'}]
2024-11-05 11:50:29.823 | INFO     | metagpt.utils.token_counter:count_input_tokens:396 - Warning: model llama3-8b-llama3-8b-instruct not found in tiktoken. Using cl100k_base encoding.
2024-11-05 11:50:30.365 | WARNING  | metagpt.provider.openai_api:_calc_usage:268 - usage calculation failed: num_tokens_from_messages() is not implemented for model llama3-8b-llama3-8b-instruct. See https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken for information on how messages are converted to tokens.
2024-11-05 11:50:30.366 | INFO     | metagpt.utils.cost_manager:update_cost:108 - prompt_tokens: 0, completion_tokens: 0
2024-11-05 11:53:06.884 | DEBUG    | metagpt.provider.base_llm:aask:151 - [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello world'}]
2024-11-05 12:06:43.725 | DEBUG    | metagpt.provider.base_llm:aask:151 - [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello world'}]
2024-11-05 12:07:50.431 | DEBUG    | metagpt.provider.base_llm:aask:151 - [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello world'}]
2024-11-05 12:09:34.365 | DEBUG    | metagpt.provider.base_llm:aask:151 - [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello world'}]
2024-11-05 12:11:52.244 | DEBUG    | metagpt.provider.base_llm:aask:151 - [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello world'}]
2024-11-05 13:47:51.532 | DEBUG    | Core.Provider.BaseLLM:aask:151 - [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello world'}]
2024-11-05 13:53:05.067 | INFO     | metagpt.utils.token_counter:count_input_tokens:396 - Warning: model llama3-8b-llama3-8b-instruct not found in tiktoken. Using cl100k_base encoding.
2024-11-05 13:53:05.483 | WARNING  | Core.Provider.OpenaiApi:_calc_usage:269 - usage calculation failed: num_tokens_from_messages() is not implemented for model llama3-8b-llama3-8b-instruct. See https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken for information on how messages are converted to tokens.
2024-11-05 13:53:05.483 | INFO     | Core.Common.CostManager:update_cost:107 - prompt_tokens: 0, completion_tokens: 0
